{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8022185",
   "metadata": {},
   "source": [
    "# Apache Sedona with PostGIS \n",
    "Apache Sedona (previously GeoSpark) is a geospatial engine for distributed computing that integrates with Apache Spark. It allow to process large geospatial datasets across clusters, integrates Spark SQL layer, provides similar queries like PostGIS, implements spatial operations and geometry based on the Java Topology Suite (JTS), provides spatial indexing (quadtree, R-tree) and batch and streaming spatial analytics.\n",
    "\n",
    "This notebook demonstrates how to use Apache Sedona linked with PostGIS for spatial data processing and analysis. \n",
    "\n",
    "**Documentation:**\n",
    "- [Apache Sedona Documentation](https://sedona.apache.org/latest/tutorial/sql/)\n",
    "- [How to create Geometries in Sedona](https://sedona.apache.org/latest-snapshot/api/sql/Constructor/) including all sorts of functions like `ST_GeomFromWKT`, `ST_GeomFromGeoJSON`, `ST_Point`, etc.\n",
    "- [Sedona Python Documentation](https://sedona.apache.org/latest/api/pydocs/index.html)\n",
    "\n",
    "**Prerequisites**\n",
    "1. Start the docker container with Apache Sedona and PostGIS installed. Either using Docker Desktop or using the command line.\n",
    "2. Once the container is running you can access the Jupyter using your web browser at `http://localhost:8888`. In case you want to use the Jupyter notebook from VS Code, open the project folder in VS Code (you may need to install the Jupyter extension). Then try to run the first code cell and you'll be prompted to select a kernel, select *Jupyter Server* connect and connect to the Jupyter server at `http://localhost:8888` and the Python 3 kernel.\n",
    "3. In case you have a PostgreSQL database locally running on your machine, stop the service on your machine to avoid port conflicts with the PostGIS database running in the Docker container.\n",
    "\n",
    "**Contents**\n",
    "This notebook covers the following topics step by step:\n",
    "\n",
    "- Initialise Sedona and Spark, and check if the connection to PostGIS is working\n",
    "- Load spatial data from PostGIS and convert it to Sedona DataFrame\n",
    "- Perform spatial queries using Sedona SQL functions\n",
    "- Load geospatial data from Parquet files and convert to geometries\n",
    "- Load geodatasets from STAC API\n",
    "- Load geoparquet files\n",
    "- Load csv files and convert to geometries \n",
    "- Visualize geospatial data using Kepler.gl and Folium\n",
    "\n",
    "\n",
    "**Files**\n",
    "- `ist-daten-sbb.parquet` via [https://data.sbb.ch](https://data.sbb.ch/explore/dataset/ist-daten-sbb/export/?flg=de)\n",
    "- `linie-mit-polygon.parquet` via [https://data.sbb.ch](https://data.sbb.ch/explore/dataset/linie-mit-polygon/export/)\n",
    "- `stop-points-today.parquet` via [https://data.oev-info.ch](https://data.oev-info.ch/explore/dataset/stop-points-today)\n",
    "- `Betriebspunkte.csv` via [https://data.geo.admin.ch](https://data.geo.admin.ch/browser/index.html#/collections/ch.bav.haltestellen-oev/)\n",
    "- `test5.diff` vis [Apache Sedona Usecases](https://github.com/apache/sedona/tree/master/docs/usecases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2179cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run of this cell takes a bit of time to set up the Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from sedona.spark import SedonaContext\n",
    "# Initialize Spark and Sedona \n",
    "# (your may need to wait a bit for the docker containers to properly start)\n",
    "spark = (SparkSession.builder.appName(\"Sedona + PostGIS\").getOrCreate())\n",
    "sedona = SedonaContext.create(spark) # initiatie Sedona context\n",
    "\n",
    "print(\"Spark:\", spark.version)\n",
    "print(\"Spark jars:\", spark.sparkContext.getConf().get(\"spark.jars\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up JDBC (Java Database Connection) connection parameters to the PostGIS database \"gis\"\n",
    "# Verify that there is not another postgres instance running on the host machine on port 5432\n",
    "jdbc_url = \"jdbc:postgresql://host.docker.internal:5432/gis\" \n",
    "# (if your too lazy to stop your local postgres instance, \n",
    "# use dockername with postgis for internal docker networking)\n",
    "# jdbc_url = \"jdbc:postgresql://sedona-postgis:5432/gis\" \n",
    "db_properties = {\"user\": \"postgres\", \n",
    "                 \"password\": \"postgres\", \n",
    "                 \"driver\": \"org.postgresql.Driver\"}\n",
    "# Test basic JDBC connection\n",
    "try:\n",
    "    test_df = (spark.read.format(\"jdbc\").option(\"url\", jdbc_url)\n",
    "               .option(\"dbtable\", \"(SELECT version())\")\n",
    "               .options(**db_properties).load())    \n",
    "    print(\"✅ Connection successful!\")\n",
    "    test_df.show(truncate=False)\n",
    "except Exception as e:\n",
    "    print(\"❌ Connection failed:\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c4ac7",
   "metadata": {},
   "source": [
    "## Import spatial data from PostGIS\n",
    "With the *query* option you can read and convert to spatial data from JDBC data sources (e.g., PostGIS). In case of PostGIS there's no need to convert the geometries, as it's already using EWKB format (see: [Load data from JDBC data sources](https://sedona.apache.org/latest/tutorial/sql/#load-data-from-jdbc-data-sources))\n",
    "\n",
    "The following code cell show three examples how to read spatial data from PostGIS.\n",
    "- Example 1: Sedona read and convert geometries\n",
    "- Example 2: Sedona read directly as spatial data from PostGIS\n",
    "- Example 3: For reference with standard Spark JDBC read (non-spatial) from PostGIS and convert.\n",
    "\n",
    "ps. the () brackets around the sedona call, are only needed to split the code into multiple lines for better readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "367ea7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Sedona read directly as spatial data from PostGIS\n",
    "from pyspark.sql import functions as f\n",
    "df = (sedona.read.format(\"jdbc\")\n",
    "      .option(\"url\", jdbc_url).options(**db_properties)    # connection parameters\n",
    "      .option(\"dbtable\", \"public.demo_polygons\").load()    # table to read\n",
    "      .withColumn(\"geom\", f.expr(\"ST_GeomFromWKB(geom)\"))) # convert to geometry\n",
    "# df.printSchema()\n",
    "# df.count()\n",
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0aecef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Sedona read and convert geometries\n",
    "sql_query = \"(SELECT id, name, ST_AsBinary(geom) AS geom FROM public.demo_polygons)\"\n",
    "df = (sedona.read.format(\"jdbc\")\n",
    "      .option(\"url\", jdbc_url).options(**db_properties)    # JDBC connection options\n",
    "      .option(\"query\", sql_query).load()                   # SQL query to read data and load data\n",
    "      .withColumn(\"geom\", f.expr(\"ST_GeomFromWKB(geom)\"))) # convert WKB to geometry\n",
    "# df.printSchema()\n",
    "# df.count()\n",
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e6d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: For reference with standard Spark JDBC read (non-spatial) from PostGIS and convert.\n",
    "# SQL query with the conversion of geometries to WKT with ST_AsText() as Spark \n",
    "# cannot natively read PostGIS geometry types\n",
    "from pyspark.sql.functions import expr\n",
    "sql_query = \"(SELECT id, name, ST_AsText(geom) AS geom FROM public.demo_polygons)\"\n",
    "df = (spark.read.format(\"jdbc\")\n",
    "             .option(\"url\", jdbc_url).options(**db_properties) # SQL query to read data and load data\n",
    "             .option(\"dbtable\",sql_query).load())\n",
    "# Convert WKT geometries to Sedona geometry types\n",
    "sedona_df = df.select(\"id\", \"name\", expr(\"ST_GeomFromWKT(geom)\").alias(\"geometry\"))\n",
    "sedona_df.show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd90bfb",
   "metadata": {},
   "source": [
    "## Sample spatial query\n",
    "The two following code cells show how to perform a spatial query using Sedona SQL functions with the data.frames loaded from PostGIS and converted to Sedona geometry types.\n",
    "\n",
    "Query: Find points within polygons.\n",
    "\n",
    "The first code cell uses Sedona SQL functions, the second code cell uses Spark SQL functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe5db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Sedona:\n",
    "from pyspark.sql import functions as f\n",
    "# Read Sedona geometries from PostGIS tables and perform spatial query\n",
    "polygons_df = (sedona.read.format(\"jdbc\")\n",
    "      .option(\"url\", jdbc_url).options(**db_properties)    # connection parameters\n",
    "      .option(\"dbtable\", \"public.demo_polygons\").load()    # table to read\n",
    "      .withColumn(\"geom\", f.expr(\"ST_GeomFromWKB(geom)\"))  # convert to geometry\n",
    "      .withColumnRenamed(\"geom\", \"geometry\"))              # rename column\n",
    "points_df = (sedona.read.format(\"jdbc\")\n",
    "      .option(\"url\", jdbc_url).options(**db_properties)    # connection parameters\n",
    "      .option(\"dbtable\", \"public.demo_points\").load()      # table to read\n",
    "      .withColumn(\"geom\", f.expr(\"ST_GeomFromWKB(geom)\"))  # convert to geometry\n",
    "      .withColumnRenamed(\"geom\", \"geometry\"))              # rename column\n",
    "# points_df.printSchema()\n",
    "# polygons_df.printSchema()\n",
    "# Create temporary views for SQL queries\n",
    "polygons_df.createOrReplaceTempView(\"polygons\")\n",
    "points_df.createOrReplaceTempView(\"points\")\n",
    "\n",
    "# Perform spatial query: Find points contained within polygons\n",
    "contained_df = sedona.sql(\"\"\"\n",
    "    SELECT\n",
    "        pnt.id        AS point_id,\n",
    "        pnt.name      AS point_name,\n",
    "        pnt.geometry  AS geometry,\n",
    "        poly.id       AS polygon_id,\n",
    "        poly.name     AS polygon_name\n",
    "    FROM points pnt\n",
    "    JOIN polygons poly\n",
    "      ON ST_Contains(poly.geometry, pnt.geometry)\n",
    "\"\"\")\n",
    "# Show results\n",
    "contained_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d757e",
   "metadata": {},
   "source": [
    "The following code cell shows how to read the with spark from PostGIS converting the geometries to WKT Strings, then convert the geometry column to Sedona geometry type using `ST_GeomFromWKB` function, and finally perform the spatial query using Sedona SQL functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ea1b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Spark:\n",
    "# SQL query with the conversion of geometries to WKT with ST_AsText() as Spark \n",
    "# cannot natively read PostGIS geometry types\n",
    "sql_query = \"(SELECT id, name, ST_AsText(geom) AS geom FROM public.demo_points)\"\n",
    "points_df = (spark.read.format(\"jdbc\")\n",
    "             .option(\"url\", jdbc_url).options(**db_properties) # SQL query to read data and load data\n",
    "             .option(\"dbtable\",sql_query).load())\n",
    "sql_query = \"(SELECT id, name, ST_AsText(geom) AS geom FROM public.demo_polygons)\"\n",
    "polygons_df = (spark.read.format(\"jdbc\")\n",
    "             .option(\"url\", jdbc_url).options(**db_properties) # SQL query to read data and load data\n",
    "             .option(\"dbtable\",sql_query).load())\n",
    "# points_df.printSchema()\n",
    "# polygons_df.printSchema()\n",
    "# Register DataFrames as Sedona spatial tables\n",
    "from pyspark.sql.functions import expr\n",
    "# Convert WKT geometries to Sedona geometry types\n",
    "sedona_polygons = polygons_df.select(\"id\", \"name\", expr(\"ST_GeomFromWKT(geom)\").alias(\"geometry\"))\n",
    "sedona_points = points_df.select(\"id\", \"name\", expr(\"ST_GeomFromWKT(geom)\").alias(\"geometry\"))\n",
    "# sedona_polygons.printSchema()\n",
    "# sedona_points.printSchema()\n",
    "# Create temporary views for SQL queries\n",
    "sedona_polygons.createOrReplaceTempView(\"polygons\")\n",
    "sedona_points.createOrReplaceTempView(\"points\")\n",
    "# Perform spatial query: Find points contained within polygons\n",
    "contained_df = sedona.sql(\"\"\"\n",
    "    SELECT\n",
    "        pnt.id        AS point_id,\n",
    "        pnt.name      AS point_name,\n",
    "        pnt.geometry  AS geometry,\n",
    "        poly.id       AS polygon_id,\n",
    "        poly.name     AS polygon_name\n",
    "    FROM points pnt\n",
    "    JOIN polygons poly\n",
    "      ON ST_Contains(poly.geometry, pnt.geometry)\n",
    "\"\"\")\n",
    "# Show results\n",
    "contained_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c0c9d",
   "metadata": {},
   "source": [
    "## Save analysis results back to PostGIS\n",
    "You may want to save analysis results back to PostGIS, to easily visualize them in a GIS software like QGIS or serve these on a web map using e.g. GeoServer.\n",
    "\n",
    "To save spatial data back to PostGIS using Sedona, the geometry column needs to be converted to EWKB format (Extended Well-Known Binary) using the `ST_AsEWKB` function. The following code cell shows how to do this (see [Save to PostGIS](https://sedona.apache.org/latest/tutorial/sql/?h=sedona.sql#save-to-postgis))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c243896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results back to PostGIS\n",
    "# https://sedona.apache.org/latest/tutorial/sql/?h=sedona.sql#save-to-postgis\n",
    "(contained_df.withColumn(\"geometry\", expr(\"ST_AsEWKB(geometry)\"))\n",
    "                        .write.format(\"jdbc\")\n",
    "                        .option(\"url\", jdbc_url).options(**db_properties)\n",
    "                        .option(\"dbtable\", \"public.points_within_polygons\") \n",
    "                        .option(\"truncate\",\"true\").mode(\"overwrite\").save())\n",
    "# Check if results have been saved correctly to PostGIS\n",
    "check_df = (sedona.read.format(\"jdbc\")\n",
    "            .option(\"url\", jdbc_url).options(**db_properties)    # connection parameters\n",
    "            .option(\"dbtable\", \"public.points_within_polygons\").load()    # table to read\n",
    "            .withColumn(\"geom\", f.expr(\"ST_GeomFromWKB(geometry)\"))) # convert to geometry\n",
    "# df.printSchema()\n",
    "# df.count()\n",
    "check_df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc0561",
   "metadata": {},
   "source": [
    "## Visualisation \n",
    "Following sections show different options to visualize geospatial data in the notebook using Matplotlib, Kepler.gl and Folium.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a05c9",
   "metadata": {},
   "source": [
    "### Visualisation with Matplotlib\n",
    "Matplotlib is useful to quickly visualise static maps in 2D. The docker image with Sedona includes Matplotlib by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sedona DataFrames to GeoPandas GeoDataFrames\n",
    "import geopandas as gpd\n",
    "polygons_pandas = polygons_df.toPandas()\n",
    "polygons_gdf = gpd.GeoDataFrame(polygons_pandas, geometry='geometry', crs='EPSG:4326')\n",
    "points_pandas = points_df.toPandas()\n",
    "points_gdf = gpd.GeoDataFrame(points_pandas, geometry='geometry', crs='EPSG:4326')\n",
    "contained_pandas = contained_df.toPandas()\n",
    "contained_gdf = gpd.GeoDataFrame(contained_pandas, geometry='geometry', crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bf1a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualise results with Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "polygons_gdf.plot(ax=ax, facecolor='none', edgecolor='darkgrey', linewidth=1, alpha=1)\n",
    "points_gdf.plot(ax=ax, color='lightgrey', markersize=20, alpha=0.8, label='All Points')\n",
    "contained_gdf.plot(ax=ax, color='lightblue', markersize=20, alpha=0.9, label='Contained Points')\n",
    "plt.title('Points within Polygons', fontsize=14)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca41c99",
   "metadata": {},
   "source": [
    "### Visualisation with Kepler.gl\n",
    "In case the Kepler.gl extension doesn't load, you may need to change settings in vs code to allow loading of widgets from external sources. Open user settings (Ctrl + ,), go to *Users / Extensions / Jupyter* scroll way down to *Widget Script Sources* and open the url pointing to `settings.json`. Include the following entry to the list of allowed sources:\n",
    "```json\n",
    "{\n",
    "    ...\n",
    "    \"python.useEnvironmentsExtension\": true,\n",
    "    \"jupyter.widgetScriptSources\": [\n",
    "        \"jsdelivr.com\",\n",
    "        \"unpkg.com\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "Restart the Kernel and if that doesn't help use the *reload Window* command from the command palette (Ctrl + Shift + P) and run the cell again (with the required previous cells executed). Or Open the notebook in the browser directly using `http://localhost:8888` and then apply *reload window* command.\n",
    "\n",
    "For the Documentation see [SedonaKepler](https://sedona.apache.org/latest/api/sql/Visualization-SedonaKepler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597031ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter labextension list\n",
    "# Load Kepler.gl map with SedonaKepler and add dataframes to display\n",
    "from sedona.spark import SedonaKepler\n",
    "map = SedonaKepler.create_map(contained_df, \"contained\")\n",
    "SedonaKepler.add_df(map, points_df, \"points\")\n",
    "SedonaKepler.add_df(map,polygons_df, \"polygons\" )\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a3476",
   "metadata": {},
   "source": [
    "### Visualisation with Folium\n",
    "Folium is a python library to create interactive maps with Leaflet.js and geopandas. The docker image with Sedona does not include Folium by default, so you need to install it first using `!pip install folium` command in a code cell and restart the kernel.\n",
    "\n",
    "Hence, to visualise sedona spatial data.frame in folium, we need to convert these to geopandas with the Geopanda API for Apache Sedona (see [Sedona GeoPandas API](https://sedona.apache.org/latest/tutorial/geopandas-api/?h=geopanda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66afc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folium is not installed by default in the Sedona docker image, and needs\n",
    "# to be installed with every restart of the docker image.\n",
    "# run the following command to install it:\n",
    "!pip install folium\n",
    "# restart the python kernel after installation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557984f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes folium doesn't work properly (grey map only) in JupyterLab,\n",
    "# in this case, restart the jupyter notebook.\n",
    "import folium\n",
    "# Create folium map\n",
    "map = folium.Map(location=[47, 8], tiles=\"CartoDB Positron\", zoom_start=9)\n",
    "folium.GeoJson(polygons_gdf).add_to(map)\n",
    "folium.GeoJson(points_gdf,\n",
    "               marker=folium.CircleMarker(radius=5, fill=True, fillColor='lightblue', \n",
    "                                          color='blue', fillOpacity=0.7)).add_to(map)\n",
    "folium.GeoJson(contained_gdf,\n",
    "               marker=folium.CircleMarker(radius=5, fill=True, fillColor='lightgreen', \n",
    "                                          color='green', fillOpacity=0.7)).add_to(map)\n",
    "folium.LayerControl().add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd3813",
   "metadata": {},
   "source": [
    "## Reading different (spatial) file formats\n",
    "Both Spark and Sedona provide reader for various file formats with slightly different notations ([Sedona Documentation](https://sedona.apache.org/latest/) under *Programming Guides / Files*, [Spark Data Sources](https://spark.apache.org/docs/latest/sql-data-sources.html)).  \n",
    "\n",
    "\n",
    "### Read Parquet files\n",
    "Reading files with the spark reader `spark.read.parquet(...)` results in a standard Spark DataFrame, while reading files with the sedona reader `sedona.read.format(\"<formatname>\").load(...)` results in a Sedona DataFrame.\n",
    "Reading spatial data from Parquet files and converting to geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58feecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Parquet Files with Spark and Sedona\n",
    "# Read the Parquet file using Spark's read API\n",
    "# rawdf = spark.read.parquet(\"/opt/workspace/data/stop-points-today.parquet\")\n",
    "# Read the Parquet with Sedona's read API\n",
    "rawdf = sedona.read.format(\"parquet\").load(\"/opt/workspace/data/stop-points-today.parquet\")\n",
    "# Display basic information\n",
    "# df.printSchema()\n",
    "rawdf.show(5)\n",
    "rawdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3762526",
   "metadata": {},
   "source": [
    "The loaded Parquet file contains coordinate columns, here named *lv95east, lv95north*. Convert these columns to geometries using the Sedona function `ST_Point(lv95east, lv95north)`. If a column contains WKT geometries, you can use the function `ST_GeomFromWKT(<wkt_column>)` to convert it to geometries. Set the correct SRID using the function `ST_SetSRID(<geometry>, <srid>)` and wrap the geometry with the ST_SetSRID function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51decdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert two columns lv95east and lv95north to a geometry column\n",
    "spatialdf = rawdf.withColumn(\"geometry\", expr(\"ST_SetSRID(ST_Point(lv95east, lv95north), 2056)\"))\n",
    "# show the new dataframe with the geometry column\n",
    "spatialdf.select(\"sloid\", \"designationofficial\", \"geometry\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51189431",
   "metadata": {},
   "source": [
    "### Read CSV files\n",
    "Read CSV-files and convert columns with coordinates to geometries the same way as in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a csv file with coordinates and convert to geometry\n",
    "# Betriebspunkt.csv \n",
    "# https://data.geo.admin.ch/browser/index.html#/collections/ch.bav.haltestellen-oev/\n",
    "csvdf = spark.read.option(\"header\", \"true\").csv(\"/opt/workspace/data/Betriebspunkt.csv\")\n",
    "# csvdf.show(5) # Show all columns\n",
    "# convert two columns E, N to a geometry column\n",
    "spatialcsv = csvdf.withColumn(\"geometry\", expr(\"ST_Point(E, N)\"))\n",
    "spatialcsv.select(\"Name\", \"Abkuerzung\", \"geometry\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dfcde",
   "metadata": {},
   "source": [
    "### Read GeoParquet files\n",
    "Sedona provides a reader for GeoParquet files. Use the sedona reader `sedona.read.format(\"geoparquet\").load(<filepath>)` to read GeoParquet files directly as Sedona DataFrame with spatial capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "357a4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "df = sedona.read.format(\"geoparquet\").load(\"/opt/workspace/data/ist-daten-sbb.parquet\")\n",
    "line_df = sedona.read.format(\"geoparquet\").load(\"/opt/workspace/data/linie-mit-polygon.parquet\")\n",
    "summary_df = (df.groupBy(\"bpuic\").agg(\n",
    "    f.sum(f.when(f.col(\"ankunftsverspatung\") == True, 1).otherwise(0)).alias(\"count_ankunftsverspatung\"),\n",
    "    f.sum(f.when(f.col(\"abfahrtsverspatung\") == True, 1).otherwise(0)).alias(\"count_abfahrtverspatung\"),\n",
    "    f.first(\"geopos\").alias(\"geometry\")\n",
    "))\n",
    "# summary_df.printSchema()\n",
    "summary_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd791f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to geopandas for visualisation\n",
    "df_pandas = summary_df.toPandas()\n",
    "gdf = gpd.GeoDataFrame(df_pandas, geometry='geometry', crs='EPSG:4326')\n",
    "line_df_pandas = line_df.toPandas()\n",
    "line_gdf = gpd.GeoDataFrame(line_df_pandas, geometry='geo_shape', crs='EPSG:4326')\n",
    "# Visualisation with Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "line_gdf.plot(ax=ax, facecolor='none', edgecolor='lightgrey', linewidth=1, alpha=1)\n",
    "gdf.plot(ax=ax, column='count_ankunftsverspatung', cmap='OrRd', markersize=20, \n",
    "         alpha=0.9, label='Number of Arrival Delays')\n",
    "# gdf.plot(figsize=(10, 8), edgecolor='blue', linewidth=2, alpha=0.6)\n",
    "plt.title('Delays', fontsize=14)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903c7ff",
   "metadata": {},
   "source": [
    "## Read GeoTIFF files\n",
    "Sedona provides a reader for GeoTIFF files. Use the sedona reader `sedona.read.format(\"geotiff\").load(<filepath>)` to read GeoTIFF files. For more details on Raster DataFrames on Sedona see [Raster DataFrame / SQL app](https://sedona.apache.org/latest/tutorial/raster/) and the notebook [ApacheSedonaRaster.ipynb](https://github.com/apache/sedona/blob/master/docs/usecases/ApacheSedonaRaster.ipynb) on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5c563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Cloud Optimized GeoTIFF from URL\n",
    "# geotiff_df = sedona.read.format(\"binaryFile\").load(\"data/swiss-map-raster1000_1000_kgrel_50_2056.tif\")\n",
    "geotiff_df = sedona.read.format(\"binaryFile\").load(\"data/test5.tiff\")\n",
    "geotiff_df.show(2)\n",
    "geotiff_df.printSchema()\n",
    "# Create a temporary view for SQL queries\n",
    "geotiff_df.createOrReplaceTempView(\"binary_raster\")\n",
    "# # Show basic information\n",
    "geotiff_df.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f53af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sedona SQL to read the GeoTIFF content as raster\n",
    "raster_df = sedona.sql(\"SELECT RS_FromGeoTiff(content) as raster from binary_raster\")\n",
    "raster_df.show(2)\n",
    "raster_df.createOrReplaceTempView(\"raster_table\")\n",
    "# Get raster metadata\n",
    "raster_metadata = sedona.sql(\"SELECT RS_MetaData(raster) as metadata from raster_table\")\n",
    "metadata = raster_metadata.first()[0]\n",
    "raster_srid = metadata[8]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedona.spark import *\n",
    "# from IPython.display import display, HTML\n",
    "SedonaUtils.display_image(raster_df.selectExpr(\"RS_AsImage(raster, 500)\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
